#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AdaptEgo è‡ªé€‚åº”æƒé‡é¢„æµ‹è®­ç»ƒè„šæœ¬ - ç‹¬ç«‹è¿è¡Œç‰ˆæœ¬
é€‚é…ROS2 Humbleç¯å¢ƒï¼Œæ”¯æŒçº¯Pythonè®­ç»ƒ
"""

import os
import sys
import time
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, TensorDataset
from torch.utils.tensorboard import SummaryWriter
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# ROS2å…¼å®¹å¯¼å…¥ - ä»…åœ¨ROSç¯å¢ƒä¸‹ä½¿ç”¨
try:
    import rclpy
    from geometry_msgs.msg import PoseStamped
    from nav_msgs.msg import Odometry
    from sensor_msgs.msg import LaserScan
    from std_msgs.msg import Float32MultiArray
    ROS_AVAILABLE = True
    print("âœ… ROS2ç¯å¢ƒå¯ç”¨")
except ImportError:
    ROS_AVAILABLE = False
    print("âš ï¸  ROS2ç¯å¢ƒä¸å¯ç”¨ï¼Œä½¿ç”¨çº¯Pythonæ¨¡å¼")

class WeightPredictorNetwork(nn.Module):
    """è‡ªé€‚åº”æƒé‡é¢„æµ‹ç½‘ç»œ"""
    
    def __init__(self, input_dim=12, output_dim=6, hidden_dims=[128, 128, 64]):
        super().__init__()
        
        # æ„å»ºå¤šå±‚ç½‘ç»œ
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            prev_dim = hidden_dim
            
        # è¾“å‡ºå±‚
        layers.append(nn.Linear(prev_dim, output_dim))
        layers.append(nn.Sigmoid())  # è¾“å‡º[0,1]ï¼Œåç»­ä¼šç¼©æ”¾
        
        self.network = nn.Sequential(*layers)
        
    def forward(self, x):
        return self.network(x)

class AdaptiveWeightTrainer:
    """è‡ªé€‚åº”æƒé‡è®­ç»ƒå™¨"""
    
    def __init__(self, model, optimizer, criterion, device):
        self.model = model
        self.optimizer = optimizer  
        self.criterion = criterion
        self.device = device
        
    def train_epoch(self, dataloader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        
        for batch_x, batch_y in dataloader:
            batch_x = batch_x.to(self.device)
            batch_y = batch_y.to(self.device)
            
            self.optimizer.zero_grad()
            
            outputs = self.model(batch_x)
            loss = self.criterion(outputs, batch_y)
            
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            
        return total_loss / len(dataloader)
    
    def validate_epoch(self, dataloader):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        
        with torch.no_grad():
            for batch_x, batch_y in dataloader:
                batch_x = batch_x.to(self.device)
                batch_y = batch_y.to(self.device)
                
                outputs = self.model(batch_x)
                loss = self.criterion(outputs, batch_y)
                
                total_loss += loss.item()
                
        return total_loss / len(dataloader)

def generate_synthetic_data(save_path, n_samples=2000):
    """ç”Ÿæˆåˆæˆä¸“å®¶æ¼”ç¤ºæ•°æ®ç”¨äºæµ‹è¯•"""
    print(f"ğŸ”„ ç”Ÿæˆ {n_samples} ä¸ªåˆæˆè®­ç»ƒæ ·æœ¬...")
    
    # ç”Ÿæˆéšæœºç¯å¢ƒçŠ¶æ€
    states = np.random.randn(n_samples, 12)
    
    # è§„èŒƒåŒ–åˆ°åˆç†èŒƒå›´
    # ä½ç½® [0, 10]
    states[:, 0:3] = states[:, 0:3] * 2 + 5
    # ç›®æ ‡ç›¸å¯¹ä½ç½® [-5, 5]  
    states[:, 3:6] = states[:, 3:6] * 2
    # ç¯å¢ƒç‰¹å¾ [0, 5]
    states[:, 6:12] = np.abs(states[:, 6:12]) * 2
    
    # åŸºäºå¯å‘å¼è§„åˆ™ç”Ÿæˆä¸“å®¶æƒé‡
    weights = np.zeros((n_samples, 6))
    
    for i in range(n_samples):
        # æå–å…³é”®ç‰¹å¾
        goal_dist = np.linalg.norm(states[i, 3:6])
        obstacle_density = states[i, 6]
        
        # ä¸“å®¶ç­–ç•¥
        # w_smooth: è·ç¦»è¶Šè¿œè¶Šéœ€è¦å¹³æ»‘
        weights[i, 0] = 0.5 + 0.5 * min(goal_dist / 10.0, 1.0)
        
        # w_collision: éšœç¢è¶Šå¤šæƒé‡è¶Šé«˜
        weights[i, 1] = 3.0 + 5.0 * min(obstacle_density / 5.0, 1.0)
        
        # w_time: åŸºç¡€æ—¶é—´æƒé‡
        weights[i, 2] = 0.3 + 0.4 * np.random.rand()
        
        # corridor_width: éšœç¢å¤šæ—¶èµ°å»Šè¦å®½
        weights[i, 3] = 0.8 + 0.5 * (1 - min(obstacle_density / 5.0, 1.0))
        
        # max_velocity: æ ¹æ®è·ç¦»å’Œéšœç¢è°ƒæ•´
        weights[i, 4] = 1.0 + 1.5 * min(goal_dist / 10.0, 1.0) * (1 - min(obstacle_density / 5.0, 1.0))
        
        # replan_freq: éšœç¢å¤šæ—¶é¢‘ç‡é«˜
        weights[i, 5] = 10.0 + 15.0 * min(obstacle_density / 5.0, 1.0)
    
    # æ·»åŠ å™ªå£°
    weights += np.random.normal(0, 0.1, weights.shape)
    
    # æ¨¡æ‹ŸæˆåŠŸç‡ï¼ˆåŸºäºæƒé‡åˆç†æ€§ï¼‰
    success = np.random.choice([0, 1], n_samples, p=[0.15, 0.85])
    
    # ä¿å­˜æ•°æ®
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    np.savez_compressed(save_path, states=states, weights=weights, success=success)
    print(f"âœ… åˆæˆæ•°æ®å·²ä¿å­˜åˆ°: {save_path}")

def plot_training_results(train_losses, val_losses):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='è®­ç»ƒæŸå¤±', linewidth=2)
    plt.plot(val_losses, label='éªŒè¯æŸå¤±', linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.title('ğŸš€ è®­ç»ƒè¿‡ç¨‹')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    plt.plot(np.log10(train_losses), label='Logè®­ç»ƒæŸå¤±', linewidth=2)
    plt.plot(np.log10(val_losses), label='LogéªŒè¯æŸå¤±', linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('Log10(MSE Loss)')
    plt.title('ğŸ” å¯¹æ•°æŸå¤±æ›²çº¿')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/training_curves.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: results/training_curves.png")
    
    # å¦‚æœæ˜¯äº¤äº’ç¯å¢ƒå°±æ˜¾ç¤º
    try:
        plt.show()
    except:
        pass

def generate_performance_report(model, X_test, y_test, weight_ranges, device):
    """ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š"""
    model.eval()
    
    with torch.no_grad():
        X_test_tensor = torch.FloatTensor(X_test).to(device)
        y_pred = model(X_test_tensor).cpu().numpy()
    
    # è®¡ç®—è¯¯å·®ç»Ÿè®¡
    mse = np.mean((y_pred - y_test) ** 2)
    mae = np.mean(np.abs(y_pred - y_test))
    
    # å„ç»´åº¦è¯¯å·®
    dim_errors = np.mean((y_pred - y_test) ** 2, axis=0)
    
    weight_names = ['å¹³æ»‘åº¦', 'é¿éšœ', 'æ—¶é—´', 'èµ°å»Šå®½åº¦', 'æœ€å¤§é€Ÿåº¦', 'é‡è§„åˆ’é¢‘ç‡']
    
    # ç”ŸæˆæŠ¥å‘Š
    report = f"""
ğŸ¯ AdaptEgo è‡ªé€‚åº”æƒé‡é¢„æµ‹æ€§èƒ½æŠ¥å‘Š
{'=' * 50}

ğŸ“Š æ•´ä½“æ€§èƒ½æŒ‡æ ‡:
  â€¢ æµ‹è¯•æ ·æœ¬æ•°é‡: {len(X_test):,}
  â€¢ å‡æ–¹è¯¯å·® (MSE): {mse:.6f}
  â€¢ å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.6f}
  â€¢ ç›¸å…³ç³»æ•°: {np.corrcoef(y_pred.flatten(), y_test.flatten())[0,1]:.4f}

ğŸ›ï¸ å„ç»´åº¦æ€§èƒ½ (å½’ä¸€åŒ–ç©ºé—´):
"""
    
    for i, name in enumerate(weight_names):
        report += f"  â€¢ {name}: MSE={dim_errors[i]:.6f}, MAE={np.mean(np.abs(y_pred[:,i] - y_test[:,i])):.6f}\n"
    
    report += f"""
ğŸ¯ å®é™…æƒé‡ç©ºé—´æ€§èƒ½ä¼°è®¡:
"""
    
    for i, name in enumerate(weight_names):
        min_val, max_val = weight_ranges[i]
        actual_mae = np.mean(np.abs(y_pred[:,i] - y_test[:,i])) * (max_val - min_val)
        report += f"  â€¢ {name}: å¹³å‡è¯¯å·® â‰ˆ {actual_mae:.4f} (èŒƒå›´: [{min_val}, {max_val}])\n"
    
    report += f"""
ğŸ† æ¨¡å‹ç‰¹ç‚¹:
  â€¢ è¾“å…¥ç»´åº¦: 12 (ç¯å¢ƒçŠ¶æ€ç‰¹å¾)
  â€¢ è¾“å‡ºç»´åº¦: 6 (EGO-Planneræƒé‡å‚æ•°)
  â€¢ ç½‘ç»œç»“æ„: 12 â†’ 128 â†’ 128 â†’ 64 â†’ 6
  â€¢ æ¿€æ´»å‡½æ•°: ReLU + Sigmoidè¾“å‡º
  â€¢ æ­£åˆ™åŒ–: Dropout(0.2) + L2æƒé‡è¡°å‡

ğŸ“ˆ æ¨èä½¿ç”¨åœºæ™¯:
  â€¢ åŠ¨æ€ç¯å¢ƒä¸‹çš„æ— äººæœºè·¯å¾„è§„åˆ’
  â€¢ éœ€è¦å®æ—¶æƒé‡è°ƒæ•´çš„åœºæ™¯
  â€¢ EGO-Plannerå‚æ•°è‡ªåŠ¨åŒ–è°ƒä¼˜

âš ï¸  æ³¨æ„äº‹é¡¹:
  â€¢ æ¨¡å‹åŸºäºä»¿çœŸæ•°æ®è®­ç»ƒï¼Œå®é™…éƒ¨ç½²æ—¶éœ€è¦åŸŸé€‚åº”
  â€¢ å»ºè®®ç»“åˆå®‰å…¨æœºåˆ¶ä½¿ç”¨
  â€¢ å®šæœŸé‡æ–°è®­ç»ƒä»¥é€‚åº”æ–°ç¯å¢ƒ

ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    # ä¿å­˜æŠ¥å‘Š
    with open('results/performance_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: results/performance_report.txt")
    print(f"ğŸ“Š æµ‹è¯•é›†MSE: {mse:.6f}, MAE: {mae:.6f}")

def main():
    """ä¸»å‡½æ•° - å®Œæ•´çš„è®­ç»ƒç®¡é“"""
    print("ğŸš€ AdaptEgo è‡ªé€‚åº”æƒé‡é¢„æµ‹è®­ç»ƒç³»ç»Ÿ")
    print("=" * 50)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs('models', exist_ok=True)
    os.makedirs('results', exist_ok=True)
    os.makedirs('logs', exist_ok=True)
    
    # 1. æ£€æŸ¥æ•°æ®
    data_path = 'data/expert_demonstrations.npz'
    if not os.path.exists(data_path):
        print("ğŸ“ æœªæ‰¾åˆ°ä¸“å®¶æ•°æ®ï¼Œç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®...")
        generate_synthetic_data(data_path, n_samples=2000)
    
    # 2. åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®...")
    try:
        data = np.load(data_path)
        states = data['states']
        weights = data['weights']
        success = data.get('success', np.ones(len(states)))
        
        print(f"   çŠ¶æ€æ•°æ®: {states.shape}")
        print(f"   æƒé‡æ•°æ®: {weights.shape}")
        print(f"   æˆåŠŸç‡: {success.mean():.2%}")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # 3. è¿‡æ»¤æˆåŠŸçš„æ•°æ®
    if 'success' in data:
        success_mask = success == 1
        states = states[success_mask]
        weights = weights[success_mask]
        print(f"âœ… ä½¿ç”¨æˆåŠŸæ ·æœ¬: {len(states)} ä¸ª")
    
    # 4. æ•°æ®æ ‡å‡†åŒ–
    print("ğŸ”„ æ•°æ®é¢„å¤„ç†...")
    state_mean = states.mean(axis=0)
    state_std = states.std(axis=0) + 1e-8
    states_norm = (states - state_mean) / state_std
    
    # æƒé‡å½’ä¸€åŒ–åˆ°[0,1]
    weight_ranges = np.array([
        [0.1, 2.0], [1.0, 10.0], [0.1, 1.0],
        [0.3, 1.5], [0.5, 3.0], [5.0, 30.0]
    ])
    weights_norm = np.zeros_like(weights)
    for i in range(6):
        min_val, max_val = weight_ranges[i]
        weights_norm[:, i] = (weights[:, i] - min_val) / (max_val - min_val)
        weights_norm[:, i] = np.clip(weights_norm[:, i], 0, 1)
    
    # 5. æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        states_norm, weights_norm, test_size=0.2, random_state=42
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=0.25, random_state=42
    )
    
    print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
    print(f"   éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
    
    # 6. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = TensorDataset(
        torch.FloatTensor(X_train), 
        torch.FloatTensor(y_train)
    )
    val_dataset = TensorDataset(
        torch.FloatTensor(X_val), 
        torch.FloatTensor(y_val)
    )
    
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)
    
    # 7. åˆ›å»ºç½‘ç»œ
    print("ğŸ§  åˆ›å»ºç¥ç»ç½‘ç»œ...")
    model = WeightPredictorNetwork(
        input_dim=12,
        output_dim=6,
        hidden_dims=[128, 128, 64]
    ).to(device)
    
    print(f"   ç½‘ç»œå‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    # 8. è®­ç»ƒé…ç½®
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', patience=10, factor=0.5
    )
    criterion = nn.MSELoss()
    
    # 9. è®­ç»ƒè¿‡ç¨‹
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    trainer = AdaptiveWeightTrainer(
        model=model,
        optimizer=optimizer,
        criterion=criterion,
        device=device
    )
    
    # TensorBoardè®°å½•
    writer = SummaryWriter('logs/adaptive_training')
    
    best_val_loss = float('inf')
    patience_counter = 0
    patience = 20
    
    train_losses = []
    val_losses = []
    
    for epoch in range(100):  # å‡å°‘åˆ°100è½®ç”¨äºå¿«é€Ÿæ¼”ç¤º
        # è®­ç»ƒ
        train_loss = trainer.train_epoch(train_loader)
        
        # éªŒè¯
        val_loss = trainer.validate_epoch(val_loader)
        
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_loss)
        
        # TensorBoardè®°å½•
        writer.add_scalar('Loss/Train', train_loss, epoch)
        writer.add_scalar('Loss/Validation', val_loss, epoch)
        writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)
        
        # æ—©åœ
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'epoch': epoch,
                'val_loss': val_loss,
                'state_mean': state_mean,
                'state_std': state_std,
                'weight_ranges': weight_ranges
            }, 'models/best_adaptive_model.pth')
        else:
            patience_counter += 1
        
        if epoch % 10 == 0:
            print(f"Epoch {epoch:3d}: Train={train_loss:.6f}, Val={val_loss:.6f}, "
                  f"LR={optimizer.param_groups[0]['lr']:.2e}")
        
        if patience_counter >= patience:
            print(f"æ—©åœäºepoch {epoch}")
            break
    
    writer.close()
    
    # 10. æœ€ç»ˆè¯„ä¼°
    print("\nğŸ“Š æœ€ç»ˆè¯„ä¼°...")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    checkpoint = torch.load('models/best_adaptive_model.pth')
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # æµ‹è¯•é›†è¯„ä¼°
    test_dataset = TensorDataset(
        torch.FloatTensor(X_test), 
        torch.FloatTensor(y_test)
    )
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
    
    test_loss = trainer.validate_epoch(test_loader)
    print(f"ğŸ¯ æµ‹è¯•é›†æŸå¤±: {test_loss:.6f}")
    
    # 11. å¯¼å‡ºTorchScriptæ¨¡å‹
    print("ğŸ’¾ å¯¼å‡ºéƒ¨ç½²æ¨¡å‹...")
    model.eval()
    dummy_input = torch.randn(1, 12).to(device)
    traced_model = torch.jit.trace(model, dummy_input)
    traced_model.save('models/adaptive_weights.ts')
    print("   TorchScriptæ¨¡å‹å·²ä¿å­˜: models/adaptive_weights.ts")
    
    # 12. å¯è§†åŒ–ç»“æœ
    plot_training_results(train_losses, val_losses)
    
    # 13. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    generate_performance_report(model, X_test, y_test, weight_ranges, device)
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print("   â€¢ models/best_adaptive_model.pth - PyTorchæ¨¡å‹")
    print("   â€¢ models/adaptive_weights.ts - TorchScriptæ¨¡å‹")
    print("   â€¢ results/training_curves.png - è®­ç»ƒæ›²çº¿")
    print("   â€¢ results/performance_report.txt - æ€§èƒ½æŠ¥å‘Š")

if __name__ == '__main__':
    main()
